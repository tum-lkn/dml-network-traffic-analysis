{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-tampa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.cm\n",
    "import warnings\n",
    "import logging\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import itertools\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes \n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "\n",
    "logging.getLogger(\"matplotlib\").setLevel(logging.FATAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-injection",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data_path_here\"\n",
    "\n",
    "PLOT_PATH = \"plot_path_here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "frameworks = [\"tf_sync\", \"horovod\", \"kungfu_ssgd\", \"kungfu_pairavg\"]\n",
    "models = [\"mobilenetv2\", \"densenet201\", \"resnet50\", \"resnet101\"]\n",
    "optimizers = [\"adam\", \"rmsprop\"]\n",
    "batch_sizes = [\"64\", \"128\", \"512\"]\n",
    "backends = [\"grpc\", \"mpi\", \"grpc_nccl\", \"gloo\", \"gloo_nccl\", \"mpi_nccl\", \"kungfu\"]\n",
    "delays = [\"normal\", \"loss_0.01\", \"loss_0.05\", \"loss_0.1\", \"loss_0.2\", \"loss_0.5\", \"loss_1\", \"loss_2\"]\n",
    "topologies = [\"ring\", \"hierarchical\", \"BINARY_TREE_STAR\", \"CLIQUE\", \"STAR\", \"TREE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-scholar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_measurements(frameworks=frameworks, models=models, optimizers=optimizers, batch_sizes=batch_sizes, \n",
    "                               backends=backends, delays=delays, topologies=topologies, path=DATA_PATH):\n",
    "    measurements = list()\n",
    "    all_dirs = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n",
    "    for directory in all_dirs:\n",
    "        fwork, mdl, opt, bsize, bckend, dly, topo = directory.split(\"-\")\n",
    "        if (fwork in frameworks) and (mdl in models) and (opt in optimizers) and (bsize in batch_sizes) and (bckend in backends) and (dly in delays) and (topo in topologies):\n",
    "            measurements.append(directory)\n",
    "    return measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-samba",
   "metadata": {},
   "source": [
    "## Communication Patterns (Fig. 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-vaccine",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for fw, topo in list(itertools.product([\"kungfu_ssgd\", \"kungfu_pairavg\"], [\"BINARY_TREE_STAR\", \"CLIQUE\", \"STAR\", \"TREE\"])) + [(\"horovod\", \"ring\")]:\n",
    "    measurements = get_available_measurements(frameworks=fw,\n",
    "                                              models=models,\n",
    "                                              optimizers=\"adam\",\n",
    "                                              batch_sizes=\"64\",\n",
    "                                              backends=backends,\n",
    "                                              delays=\"normal\",\n",
    "                                              topologies=topo)\n",
    "    data = dict()\n",
    "    piv = 0\n",
    "    for directory in measurements:\n",
    "        data[directory] = pd.read_json(path_or_buf=os.path.join(DATA_PATH, directory, \"parsed-files\", \"joint_sent_received.json\"))\n",
    "        piv += pd.pivot_table(data[directory], values=\"frame.len\",index=[\"ip.src\"], columns=[\"ip.dst\"], fill_value=0)\n",
    "\n",
    "    piv = piv / (len(data.keys())*1e9)\n",
    "\n",
    "    piv.rename({\"192.168.17.50\": \"W1\", \"192.168.17.51\": \"W2\", \"192.168.17.52\": \"W3\", \"192.168.17.53\": \"W4\"}, inplace=True)\n",
    "    piv.columns = [\"W1\", \"W2\", \"W3\", \"W4\"]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax = sns.heatmap(piv, square=True, cmap='Blues', cbar_kws={'label': 'Tx. Volume [GB]'}, norm=LogNorm(vmin=1, vmax=500))\n",
    "    ax.set_xlabel(\"Destination\")\n",
    "    ax.set_ylabel(\"Source\")#\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=0)\n",
    "    plt.setp(ax.yaxis.get_majorticklabels(), rotation=0)\n",
    "    plt.savefig(f\"{PLOT_PATH}/comm_pattern/{fw}_{topo}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-driver",
   "metadata": {},
   "source": [
    "## Batchsize Effect (Fig. 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-saturday",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "msr = get_available_measurements(frameworks=\"horovod\", optimizers=\"adam\", models=\"mobilenetv2\", backends=\"mpi\", batch_sizes=[\"64\", \"128\",\"512\"])\n",
    "\n",
    "util = dict()\n",
    "for run in msr:\n",
    "    print(run)\n",
    "    util[run] = pd.read_json(path_or_buf=os.path.join(DATA_PATH, run, \"parsed-files\", \"utilization.json\"))\n",
    "    util[run] = util[run]*8/1e6\n",
    "    util[run].columns = [\"Worker0-Worker1\", \"Worker0-Worker2\", \"Worker0-Worker3\", \"Worker1-Worker0\", \"Worker1-Worker2\", \"Worker1-Worker3\", \"Worker2-Worker0\", \"Worker2-Worker1\", \"Worker2-Worker3\", \"Worker3-Worker0\", \"Worker3-Worker1\", \"Worker3-Worker2\"]\n",
    "    util[run].reset_index(inplace=True)\n",
    "    util[run].index = pd.TimedeltaIndex(util[run].index*1e6)\n",
    "    util[run].drop(\"index\", axis=1, inplace=True)\n",
    "    util[run] = util[run].resample('0.01S').sum()\n",
    "    util[run] = util[run]/10\n",
    "    util[run] = util[run][[\"Worker0-Worker1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-military",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1)\n",
    "\n",
    "plot_params = {\n",
    "    'markevery': 5,\n",
    "    'markersize': 4,\n",
    "    'legend': False\n",
    "}\n",
    "\n",
    "util['horovod-mobilenetv2-adam-64-mpi-normal-ring'][9495:9520].plot(ax=ax[0], zorder=3, color=\"midnightblue\", marker='o', **plot_params)\n",
    "util['horovod-mobilenetv2-adam-128-mpi-normal-ring'][9495:9520].plot(ax=ax[1], zorder=3, color=\"cadetblue\", marker='x', **plot_params)\n",
    "util['horovod-mobilenetv2-adam-512-mpi-normal-ring'][9495:9520].plot(ax=ax[2], zorder=3, color=\"darkgreen\", marker='*', **plot_params)\n",
    "\n",
    "ax[0].set_yticklabels([])\n",
    "ax[1].set_yticklabels([])\n",
    "ax[2].set_yticklabels([])\n",
    "\n",
    "handles = list()\n",
    "h, _ = ax[0].get_legend_handles_labels()\n",
    "\n",
    "handles.append(h[0])\n",
    "h, _ = ax[1].get_legend_handles_labels()\n",
    "handles.append(h[0])\n",
    "h, _ = ax[2].get_legend_handles_labels()\n",
    "handles.append(h[0])\n",
    "\n",
    "ax[0].legend(handles, [\"64\", \"128\", \"512\"],\n",
    "          bbox_to_anchor=(0.3, 1), loc='lower left', ncol=3, \n",
    "          frameon=False, columnspacing=0.4, handlelength=1.0, handletextpad=0.2, fontsize=11)\n",
    "for i in range(3):\n",
    "    ax[i].grid(color = 'gray', linestyle = '--', linewidth = 0.5, zorder=0)\n",
    "\n",
    "ax[0].set_xticklabels([])\n",
    "ax[1].set_xticklabels([])\n",
    "ax[2].set_xticklabels([0, 50, 100, 150, 200])\n",
    "ax[2].set_xlabel('Time (ms)')\n",
    "ax[1].set_ylabel('Throughput [Gbps]')\n",
    "\n",
    "\n",
    "fig.subplots_adjust(left=.18, bottom=.28, right=.99, top=.82)\n",
    "plt.savefig(f\"{PLOT_PATH}/batchsize_effect.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "natural-terrorism",
   "metadata": {},
   "source": [
    "## Analysis Packet Loss (Fig. 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "msr = get_available_measurements(frameworks=\"tf_sync\",\n",
    "                                 models=\"mobilenetv2\",\n",
    "                                 optimizers=\"adam\",\n",
    "                                 backends=\"grpc_nccl\",\n",
    "                                 batch_sizes=\"64\",\n",
    "                                 delays=[\"loss_0.01\", \"loss_0.1\", \"loss_1\", \"loss_2\"],\n",
    "                                 topologies=\"ring\") + ['tf_sync-mobilenetv2-adam-64-grpc_nccl-normal-ring']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-windows",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mydict = dict()\n",
    "for run in msr:\n",
    "    x = pd.read_csv(os.path.join(DATA_PATH, run, \"train_history.log\"))\n",
    "    mydict[run] = (x[\"Timestamp\"].max() - x[\"Timestamp\"].min())/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-quebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame.from_dict(mydict.items())\n",
    "x.index = [\"2\\%\", \"0.01\\%\", \"1\\%\", \"0.1\\%\", \"0\\%\"]\n",
    "x.columns = [\"fw\", \"min\"]\n",
    "x = x[[\"min\"]]\n",
    "x = x.reindex([\"0\\%\", \"0.01\\%\", \"0.1\\%\", \"1\\%\", \"2\\%\"])\n",
    "x = x/x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-blank",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x.plot.barh(legend=False, ax=ax, color=\"midnightblue\")\n",
    "ax.set_xticks(ticks=[i for i in range(1,11)])\n",
    "ax.grid(color = 'gray', linestyle = '--', linewidth = 0.5, zorder=0)\n",
    "ax.axvspan(2, 3, facecolor='gray', alpha=0.2)\n",
    "ax.axvspan(4, 5, facecolor='gray', alpha=0.2)\n",
    "ax.axvspan(6, 7, facecolor='gray', alpha=0.2)\n",
    "ax.axvspan(8, 9, facecolor='gray', alpha=0.2)\n",
    "ax.set_xlabel(\"Normalized Training Duration\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "\n",
    "plt.savefig(f\"{PLOT_PATH}/loss_simtime.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-overall",
   "metadata": {},
   "source": [
    "## Accelerator Comparison (Table II)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-rings",
   "metadata": {},
   "outputs": [],
   "source": [
    "msr = [\n",
    "    f\"{DATA_PATH}/{run}\" for run in [\n",
    "        \"tf_sync-resnet50-adam-64-grpc-normal-ring\", \n",
    "        \"tf_sync-resnet50-adam-64-grpc_nccl-normal-ring\", \n",
    "        \"horovod-resnet50-adam-64-mpi-normal-ring\", \n",
    "        \"horovod-resnet50-adam-64-mpi_nccl-normal-ring\",\n",
    "        \"horovod-resnet50-adam-64-gloo-normal-ring\", \n",
    "        \"horovod-resnet50-adam-64-gloo_nccl-normal-ring\", \n",
    "        \"kungfu_ssgd-resnet50-adam-64-kungfu-normal-BINARY_TREE_STAR\",\n",
    "        \"kungfu_pairavg-resnet50-adam-64-kungfu-normal-BINARY_TREE_STAR\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "util = dict()\n",
    "for run in msr:\n",
    "    util[run] = pd.read_json(path_or_buf=os.path.join(run, \"parsed-files\", \"utilization.json\"))\n",
    "    util[run] = util[run]*8/1e6\n",
    "    try:\n",
    "        util[run].columns = [\"Worker0-Worker1\", \"Worker0-Worker2\", \"Worker0-Worker3\", \"Worker1-Worker0\", \"Worker1-Worker2\", \"Worker1-Worker3\", \"Worker2-Worker0\",\n",
    "                             \"Worker2-Worker1\", \"Worker2-Worker3\", \"Worker3-Worker0\", \"Worker3-Worker1\", \"Worker3-Worker2\"]\n",
    "    except ValueError:\n",
    "        util[run].columns = [\"Worker0-Worker1\", \"Worker0-Worker2\", \"Worker1-Worker0\", \"Worker1-Worker3\", \"Worker2-Worker0\", \"Worker3-Worker1\"]\n",
    "    util[run].reset_index(inplace=True)\n",
    "    util[run].index = pd.TimedeltaIndex(util[run].index*1e6)\n",
    "    util[run].drop(\"index\", axis=1, inplace=True)\n",
    "    util[run] = util[run].resample('0.01S').sum()\n",
    "    util[run] = util[run]/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dict()\n",
    "for run in msr:\n",
    "    y[run] = list()\n",
    "    for i in range(30):\n",
    "        y[run].append(np.mean(util[run][[\"Worker0-Worker1\"]][9000+100*i:9100+100*i]))\n",
    "    m = np.mean(y[run])\n",
    "    std = math.sqrt(np.var(y[run]))\n",
    "    y[run] = [round(m - 1.96 * (std/10), 2), round(m, 2), round(m + 1.96 * (std/10), 2)]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-guatemala",
   "metadata": {},
   "source": [
    "## Temporal Flow Plot (Fig. 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flow_plot(mydict, fig, ax):\n",
    "    df = dict()\n",
    "    v_min = 0.1\n",
    "    v_max = 0\n",
    "    for flow in mydict.keys():\n",
    "        df[flow] = pd.read_json(mydict[flow])\n",
    "        df[flow].sort_index(inplace=True)\n",
    "        v_max = max(v_max, int(df[flow][\"frame.len\"].max()))\n",
    "\n",
    "    cmap = plt.cm.Blues\n",
    "\n",
    "    for (i, flow) in enumerate(mydict.keys()):\n",
    "        for idx in range(len(df[flow].index)):\n",
    "            opa = df[flow][\"frame.len\"][df[flow].index[idx]] / v_max\n",
    "            ax.broken_barh([(df[flow].index[idx], 10)], (5*(i+1), 4), facecolors=cmap(opa))\n",
    "\n",
    "\n",
    "    ax.set_ylim(0, 5 * len(mydict.keys()) + 10)\n",
    "    ax.set_xlim(0, df[flow].index[-1].max()*1.05) \n",
    "    ax.set_yticks([5*(i+1) + 2.5 for i in range(len(mydict.keys()))])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_ylabel('Flows')\n",
    "    ax.set_xlabel('Time (Sec)')\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = [\n",
    "    f\"{DATA_PATH}/tf_sync-resnet50-adam-64-grpc-normal-ring/parsed-files/temporal_flow.json\",\n",
    "    f\"{DATA_PATH}/horovod-resnet50-adam-64-mpi-normal-ring/parsed-files/temporal_flow.json\",\n",
    "    f\"{DATA_PATH}/kungfu_ssgd-resnet50-adam-64-kungfu-normal-BINARY_TREE_STAR/parsed-files/temporal_flow.json\",\n",
    "    f\"{DATA_PATH}/kungfu_pairavg-resnet50-adam-64-kungfu-normal-BINARY_TREE_STAR/parsed-files/temporal_flow.json\"\n",
    "]\n",
    "fws = [\"tf_sync\", \"horovod\", \"kungfu_ssgd\", \"kungfu_pairavg\"]\n",
    "for (run, fw) in zip(runs, fws):\n",
    "    \n",
    "    f = open(run)\n",
    "    data = json.load(f)\n",
    "    mydict = dict(data)\n",
    "    \n",
    "    if fw == \"kungfu_pairavg\":\n",
    "        fig, ax = plt.subplots()\n",
    "        get_flow_plot(mydict, fig, ax)\n",
    "        sm = matplotlib.cm.ScalarMappable(cmap=plt.cm.Blues)\n",
    "        sm.set_array([])\n",
    "        fig.colorbar(sm, ax=ax,label=\"Normalized Load\")\n",
    "        plt.savefig(f\"{PLOT_PATH}/temporal_flow/{fw}.pdf\")\n",
    "    else:\n",
    "        fig, ax = plt.subplots()\n",
    "        get_flow_plot(mydict, fig, ax)\n",
    "        plt.savefig(f\"{PLOT_PATH}/temporal_flow/{fw}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-basement",
   "metadata": {},
   "source": [
    "## Number of Flows (Fig. 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-office",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "no_flows = pd.read_json(path_or_buf=os.path.join(DATA_PATH, \"number_flows.json\"))\n",
    "measurements = get_available_measurements(frameworks=[\"tf_sync\"], models=models, optimizers=optimizers, batch_sizes=\"64\", \n",
    "                               backends=[\"grpc\"], delays=[\"normal\"], topologies=[\"ring\"])\n",
    "measurements += get_available_measurements(frameworks=[\"horovod\"], models=models, optimizers=optimizers, batch_sizes=\"64\", \n",
    "                               backends=[\"mpi\"], delays=[\"normal\"], topologies=[\"ring\"])\n",
    "measurements += get_available_measurements(frameworks=[\"kungfu_ssgd\"], topologies=\"TREE\", batch_sizes=\"64\")\n",
    "measurements += get_available_measurements(frameworks=[\"kungfu_pairavg\"], topologies=\"TREE\", batch_sizes=\"64\")\n",
    "no_flows = no_flows.loc[measurements]\n",
    "no_flows = no_flows.sort_index()\n",
    "out = pd.DataFrame()\n",
    "\n",
    "for framework in frameworks:\n",
    "    fm = no_flows.filter(like=framework, axis=0)[\"flows\"].to_frame()    \n",
    "    fm.index = [\"DenseNet201\", \"MobileNetv2\", \"ResNet101\", \"ResNet50\"]\n",
    "    fm = fm.reindex([\"MobileNetv2\", \"DenseNet201\", \"ResNet50\", \"ResNet101\"])\n",
    "    fm.columns = [framework]\n",
    "    out = pd.concat([out, fm], axis=1)\n",
    "\n",
    "measurements = get_available_measurements(frameworks=[\"kungfu_ssgd\"], topologies=\"CLIQUE\", batch_sizes=\"64\")\n",
    "measurements += get_available_measurements(frameworks=[\"kungfu_pairavg\"], topologies=\"CLIQUE\", batch_sizes=\"64\")\n",
    "no_flows = no_flows.loc[measurements]\n",
    "no_flows = no_flows.sort_index()\n",
    "\n",
    "for fw in [\"kungfu_ssgd\", \"kungfu_pairavg\"]:\n",
    "    fm = no_flows.filter(like=fw, axis=0)\n",
    "    fm = fm.filter(like=\"CLIQUE\", axis=0)[\"flows\"].to_frame()\n",
    "    fm.index = [\"DenseNet201\", \"MobileNetv2\", \"ResNet101\", \"ResNet50\"]\n",
    "    fm = fm.reindex([\"MobileNetv2\", \"DenseNet201\", \"ResNet50\", \"ResNet101\"])\n",
    "    fm.columns = [f\"{fw}clique\"]\n",
    "    out = pd.concat([out, fm], axis=1)\n",
    "    \n",
    "\n",
    "out.columns = [\"TensorFlow\", \"Horovod\", \"KungFu \\n(S-SGD)\", \"KungFu \\n(PairAvg)\", \"KungFu \\n(S-SGD) \\n[Clique]\", \"KungFu \\n(PairAvg) \\n[Clique]\"]\n",
    "out = out.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-chosen",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "out.plot(kind=\"bar\", ax=ax, rot=0, color=[\"midnightblue\", \"cadetblue\", \"skyblue\", \"dodgerblue\"], zorder=3)\n",
    "ax.set_xlabel('Frameworks')\n",
    "ax.set_ylabel('No. Flows')\n",
    "ax.legend(bbox_to_anchor=(0.5, 1.2), loc='upper center', ncol=4, frameon=False, columnspacing=0.8, handlelength=1)\n",
    "ax.grid(color = 'gray', linestyle = '--', linewidth = 0.5, zorder=0)\n",
    "ax.axvspan(0.5, 1.5, facecolor='gray', alpha=0.2)\n",
    "ax.axvspan(2.5, 3.5, facecolor='gray', alpha=0.2)\n",
    "ax.axvspan(4.5, 5.5, facecolor='gray', alpha=0.2)\n",
    "plt.savefig(f\"{PLOT_PATH}/no_flows.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-maximum",
   "metadata": {},
   "source": [
    "## Data Transferred (Fig. 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-strategy",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bytes_sent = pd.read_json(path_or_buf=os.path.join(DATA_PATH, \"bytes_sent.json\"))\n",
    "data = dict()\n",
    "for framework in frameworks:\n",
    "    if framework == \"kungfu_ssgd\" or \"kungfu_pairavg\":\n",
    "        bytes_sent_sync = bytes_sent.filter(like=framework, axis=1)\n",
    "        bytes_sent_sync = bytes_sent_sync.filter(like=\"adam-64-kungfu-normal-TREE\", axis=1)\n",
    "    if framework == \"tf_sync\":\n",
    "        bytes_sent_sync = bytes_sent.filter(like=framework, axis=1)\n",
    "        bytes_sent_sync = bytes_sent_sync.filter(like=\"adam-64-grpc-normal-ring\", axis=1)\n",
    "    if framework == \"horovod\":\n",
    "        bytes_sent_sync = bytes_sent.filter(like=framework, axis=1)\n",
    "        bytes_sent_sync = bytes_sent_sync.filter(like=\"adam-64-mpi-normal-ring\", axis=1)\n",
    "    bytes_sent_sync = bytes_sent_sync/1e9\n",
    "    bytes_sent_sync.columns = [f\"{framework}-{x.split('-')[1]}\" for x in bytes_sent_sync]\n",
    "    bytes_sent_sync.rename(columns={f'{framework}-resnet50': 'ResNet50', f'{framework}-resnet101': 'ResNet101', f'{framework}-mobilenetv2': 'MobileNetv2', f'{framework}-densenet201': 'DenseNet201'}, inplace=True)\n",
    "    data[framework] = bytes_sent_sync.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-environment",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "    \n",
    "x = pd.DataFrame(data)\n",
    "x = x[~x.index.str.contains(\"vgg16\")]\n",
    "x = x.reindex([\"MobileNetv2\", \"DenseNet201\", \"ResNet50\", \"ResNet101\"])\n",
    "\n",
    "x.plot(kind=\"bar\", rot=15, ax=ax, color=[\"midnightblue\", \"cadetblue\", \"skyblue\", \"dodgerblue\"], zorder=3)\n",
    "ax.legend([\"TensorFlow\", \"Horovod\", \"KungFu (S-SGD)\", \"KungFu (PairAvg)\"], loc='upper left', frameon=False)\n",
    "ax.grid(color = 'gray', linestyle = '--', linewidth = 0.5, zorder=0)\n",
    "ax.axvspan(0.5, 1.5, facecolor='gray', alpha=0.2)\n",
    "ax.axvspan(2.5, 3.5, facecolor='gray', alpha=0.2)\n",
    "ax.set_xlabel(\"Model\")\n",
    "ax.set_ylabel(\"Total Transmitted Volume [GB]\")\n",
    "\n",
    "\n",
    "ax2=ax.twinx()\n",
    "ax2.plot([\"MobileNetv2\", \"DenseNet201\", \"ResNet50\", \"ResNet101\"], [14, 80, 98, 171], 'r-o')\n",
    "ax2.set_ylabel(\"Model Size [MB]\")\n",
    "ax2.yaxis.label.set_color('r')\n",
    "ax2.spines['right'].set_color('r')\n",
    "ax2.tick_params(axis='y', colors='r')\n",
    "plt.savefig(f\"{PLOT_PATH}/data_transferred.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-application",
   "metadata": {},
   "source": [
    "## Link Utilization (Fig. 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-hotel",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements = get_available_measurements(frameworks=[\"tf_sync\"], models=\"mobilenetv2\", optimizers=optimizers, batch_sizes=\"64\", \n",
    "                               backends=[\"grpc\"], delays=[\"normal\"], topologies=[\"ring\"])\n",
    "measurements += get_available_measurements(frameworks=[\"horovod\"], models=\"mobilenetv2\", optimizers=optimizers, batch_sizes=\"64\", \n",
    "                               backends=[\"mpi\"], delays=[\"normal\"], topologies=[\"ring\"])\n",
    "measurements += get_available_measurements(frameworks=[\"kungfu_ssgd\"], models=\"mobilenetv2\", topologies=\"TREE\", batch_sizes=\"64\")\n",
    "measurements += get_available_measurements(frameworks=[\"kungfu_pairavg\"], models=\"mobilenetv2\", topologies=\"TREE\", batch_sizes=\"64\")\n",
    "\n",
    "util = dict()\n",
    "\n",
    "for run in measurements:\n",
    "    util[run] = pd.read_json(path_or_buf=os.path.join(DATA_PATH, run, \"parsed-files\", \"utilization.json\"))\n",
    "    util[run] = util[run]*8/1e6\n",
    "    try:\n",
    "        util[run].columns = [\"W1-W2\", \"W1-W3\", \"W1-W4\", \"W2-W1\", \"W2-W3\", \"W2-W4\", \"W3-W1\", \"W3-W2\", \"W3-W4\", \"W4-W1\", \"W4-W2\", \"W4-W3\"]\n",
    "    except ValueError:\n",
    "        util[run].columns = [\"W1-W2\", \"W1-W3\", \"W2-W1\", \"W2-W4\", \"W3-W1\", \"W4-W2\"]\n",
    "    util[run].reset_index(inplace=True)\n",
    "    util[run].index = pd.TimedeltaIndex(util[run].index*1e6)\n",
    "    util[run].drop(\"index\", axis=1, inplace=True)\n",
    "    util[run] = util[run].resample('0.01S').sum()\n",
    "    util[run] = util[run]/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-apple",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "fworks = [\"horovod\", \"kungfu_pairavg\"]\n",
    "plots = list()\n",
    "for i, ax in enumerate(axs):\n",
    "    \n",
    "    if fworks[i] == \"horovod\":\n",
    "        cols = [\"W1-W2\", \"W1-W3\", \"W1-W4\", \"W2-W1\", \"W2-W3\", \"W2-W4\", \"W3-W1\", \"W3-W2\", \"W3-W4\", \"W4-W1\", \"W4-W2\", \"W4-W3\"]\n",
    "        util[f\"{fworks[i]}-mobilenetv2-adam-64-mpi-normal-ring\"] = util[f\"{fworks[i]}-mobilenetv2-adam-64-mpi-normal-ring\"][cols]\n",
    "        myplt = util[f\"{fworks[i]}-mobilenetv2-adam-64-mpi-normal-ring\"][9000:9025].plot(ax=ax, legend=False, zorder=3)\n",
    "        plots.append(myplt)\n",
    "    elif fworks[i] == \"kungfu_ssgd\":\n",
    "        cols = [\"W1-W2\", \"W1-W3\", \"W2-W1\", \"W2-W4\", \"W3-W1\", \"W4-W2\"]\n",
    "        util[f\"{fworks[i]}-mobilenetv2-adam-64-kungfu-normal-TREE\"] = util[f\"{fworks[i]}-mobilenetv2-adam-64-kungfu-normal-TREE\"][cols]\n",
    "        myplt = util[f\"{fworks[i]}-mobilenetv2-adam-64-kungfu-normal-TREE\"][9000:9025].plot(ax=ax, legend=False, zorder=3)\n",
    "        plots.append(myplt)\n",
    "    elif fworks[i] == \"kungfu_pairavg\":\n",
    "        cols = [\"W1-W2\", \"W1-W3\", \"W1-W4\", \"W2-W1\", \"W2-W3\", \"W2-W4\", \"W3-W1\", \"W3-W2\", \"W3-W4\", \"W4-W1\", \"W4-W2\", \"W4-W3\"]\n",
    "        util[f\"{fworks[i]}-mobilenetv2-adam-64-kungfu-normal-TREE\"] = util[f\"{fworks[i]}-mobilenetv2-adam-64-kungfu-normal-TREE\"][cols]\n",
    "        myplt = util[f\"{fworks[i]}-mobilenetv2-adam-64-kungfu-normal-TREE\"][9000:9025].plot(ax=ax, legend=False, zorder=3)\n",
    "        plots.append(myplt)\n",
    "        \n",
    "    ax.set_xlabel('Time (ms)')\n",
    "    ax.set_ylabel('Throughput [Gbps]')\n",
    "    ax.set_xticklabels([0, 50, 100, 150, 200])\n",
    "    ax.set_ylim([0, 8])\n",
    "    ax.grid(color = 'gray', linestyle = '--', linewidth = 0.5, zorder=0)\n",
    "    w = (ax.get_xlim()[1] - ax.get_xlim()[0])*5/24\n",
    "    ax.axvspan(ax.get_xlim()[0] + w, ax.get_xlim()[0] + 2*w, facecolor='gray', alpha=0.2)\n",
    "    ax.axvspan(ax.get_xlim()[0] + 3*w, ax.get_xlim()[0] + 4*w, facecolor='gray', alpha=0.2)\n",
    "fig.legend(plots, labels=[\"W1-W2\", \"W1-W3\", \"W1-W4\", \"W2-W1\", \"W2-W3\", \"W2-W4\", \"W3-W1\", \"W3-W2\", \"W3-W4\", \"W4-W1\", \"W4-W2\", \"W4-W3\"], bbox_to_anchor=(0.52, 1.12), loc='upper center', ncol=6, frameon=False, columnspacing=1.5, handlelength=1.5)\n",
    "fig.text(0.3, -0.012, \"(a) Synchronous.\", ha='center')\n",
    "fig.text(0.78, -0.012, \"(b) Asynchronous.\", ha='center')\n",
    "plt.savefig(f\"figures/linkutil_v2.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-fifteen",
   "metadata": {},
   "source": [
    "## Accuracy (Fig. 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(model, path):\n",
    "    mydf = pd.read_csv(os.path.join(path, model, \"train_history.log\"))\n",
    "    mydf = mydf[mydf.Type != \"Epoch\"]\n",
    "    mydf.Timestamp += 7200\n",
    "    mydf['date'] = pd.to_datetime(mydf['Timestamp'], unit='s')\n",
    "    mydf = mydf[[\"date\", \"Accuracy\"]]\n",
    "    x = pd.read_json(path_or_buf=os.path.join(path, model, \"parsed-files\", \"bytes_per_sec.json\"))\n",
    "    x['date'] = pd.to_datetime(x['frame.time'], unit='ms')\n",
    "    x = x[[\"date\", \"frame.len\"]]\n",
    "    x = x.resample(np.mean(mydf[\"date\"].diff()), on='date').sum()\n",
    "    x[\"cum\"] = (x[\"frame.len\"].cumsum()) / 1e9\n",
    "    mydf = mydf.set_index(\"date\")\n",
    "    name = model\n",
    "    return mydf, x, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-triple",
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = {\"tf_sync\": \"TensorFlow\", \"horovod\": \"Horovod\", \"kungfu_ssgd\": \"KungFu (S-SGD)\", \"kungfu_pairavg\": \"KungFu (PairAvg)\"}\n",
    "models = [\"mobilenetv2\", \"densenet201\", \"resnet50\", \"resnet101\"]\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 4)\n",
    "plots = list()\n",
    "\n",
    "color_mappings = {\"tf_sync\": \"midnightblue\",\"horovod\": \"cadetblue\",\"kungfu_ssgd\": \"skyblue\",\"kungfu_pairavg\": \"dodgerblue\"}\n",
    "\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    \n",
    "    lgd = list()\n",
    "    runs = [f'tf_sync-{models[i]}-adam-64-grpc_nccl-normal-ring', f'horovod-{models[i]}-adam-64-mpi-normal-ring', \n",
    "            f'kungfu_ssgd-{models[i]}-adam-64-kungfu-normal-TREE', f'kungfu_pairavg-{models[i]}-adam-64-kungfu-normal-TREE']\n",
    "    for run in runs:\n",
    "        x, y, model = get_data(run, DATA_PATH)\n",
    "        fwork = model.split(\"-\")[0]\n",
    "        model = model.split(\"-\")[1]\n",
    "        try:\n",
    "            myplt = ax.plot(y[\"cum\"], x.Accuracy, color=color_mappings[fwork], zorder=3)\n",
    "            myplt.append(plots)\n",
    "            lgd.append(fwork)\n",
    "            print(colors)\n",
    "        except ValueError:\n",
    "            for i in range(3000):\n",
    "                try:\n",
    "                    myplt = ax.plot(y[\"cum\"][i:len(y[\"cum\"])], x.Accuracy, color=color_mappings[fwork], zorder=3)\n",
    "                    myplt.append(plots)\n",
    "                    lgd.append(fwork)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "    ax.set_xlabel(\"Data Transmitted [GB]\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    ax.axhline(0.6, ls='--', color=\"black\", alpha=0.9)\n",
    "    ax.axhline(0.8, ls='--', color=\"black\", alpha=0.9)\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.set_yticks(ticks=[0.2, 0.4, 0.6, 0.8])\n",
    "    if model == \"mobilenetv2\":\n",
    "        ax.set_xticks(ticks=[0, 50, 100, 150, 200])\n",
    "        ax.grid(color = 'gray', linestyle = '--', linewidth = 0.5, zorder=0)\n",
    "        ax.axvspan(50, 100, facecolor='gray', alpha=0.2)\n",
    "        ax.axvspan(150, 200, facecolor='gray', alpha=0.2)\n",
    "    if model == \"densenet201\":\n",
    "        ax.set_xticks(ticks=[0, 500, 1000, 1500, 2000])\n",
    "        ax.grid(color = 'gray', linestyle = '--', linewidth = 0.5, zorder=0)\n",
    "        ax.axvspan(500, 1000, facecolor='gray', alpha=0.2)\n",
    "        ax.axvspan(1500, 2000, facecolor='gray', alpha=0.2)\n",
    "    if model == \"resnet50\":\n",
    "        ax.set_xticks(ticks=[0, 500, 1000, 1500, 2000])\n",
    "        ax.grid(color = 'gray', linestyle = '--', linewidth = 0.5, zorder=0)\n",
    "        ax.axvspan(500, 1000, facecolor='gray', alpha=0.2)\n",
    "        ax.axvspan(1500, 2000, facecolor='gray', alpha=0.2)\n",
    "    if model == \"resnet101\":\n",
    "        ax.set_xticks(ticks=[0, 1000, 2000, 3000, 4000])\n",
    "        ax.grid(color = 'gray', linestyle = '--', linewidth = 0.5, zorder=0)\n",
    "        ax.axvspan(1000, 2000, facecolor='gray', alpha=0.2)\n",
    "        ax.axvspan(3000, 4000, facecolor='gray', alpha=0.2)\n",
    "    \n",
    "    \n",
    "fig.legend(plots, labels=[\"TensorFlow\", \"Horovod\", \"KungFu (S-SGD)\", \"KungFu (PairAvg)\"], bbox_to_anchor=(0.5, 1.08), loc='upper center', ncol=4, frameon=False)\n",
    "fig.text(0.15, -0.014, \"(a) MobileNetv2.\", ha='center')\n",
    "fig.text(0.40, -0.014, \"(b) DenseNet201.\", ha='center')\n",
    "fig.text(0.64, -0.014, \"(c) ResNet50.\", ha='center')\n",
    "fig.text(0.88, -0.014, \"(d) ResNet101.\", ha='center')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"figures/accuracy.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-pendant",
   "metadata": {},
   "source": [
    "## Throughput Table (Table I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    "msr = get_available_measurements(frameworks=\"kungfu_pairavg\", delays=\"normal\", batch_sizes=\"64\", backends=\"kungfu\")\n",
    "out = dict()\n",
    "tput = dict()\n",
    "for run in msr:\n",
    "    tput[run] = pd.read_json(path_or_buf=os.path.join(DATA_PATH, run, \"parsed-files\", \"bytes_per_sec.json\"))\n",
    "    tput[run] = tput[run]*8/1e6\n",
    "    tput[run].index = pd.TimedeltaIndex(tput[run].index*1e6)\n",
    "    tput[run] = tput[run].resample('S').sum()\n",
    "    tput[run] = tput[run]/1000\n",
    "    tput[run] = tput[run].reset_index()\n",
    "    tput[run] = tput[run][[\"frame.len\"]]\n",
    "    m = float(tput[run][200:300].mean())\n",
    "    std = math.sqrt(tput[run][200:300].var())\n",
    "    out[run] = [round(m - 1.96 * (std/10), 2), round(m, 2), round(m + 1.96 * (std/10), 2)]\n",
    "out "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-geneva",
   "metadata": {},
   "source": [
    "## Data Transmitted vs Step (Sec. VI - Prediction Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-munich",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = get_available_measurements(frameworks=frameworks, models=models, optimizers=\"adam\", batch_sizes=batch_sizes, \n",
    "                                        backends=backends, delays=\"normal\", topologies=topologies, path=DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-castle",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = dict()\n",
    "for run in all_models:\n",
    "    mydf = pd.read_csv(os.path.join(DATA_PATH, run, \"train_history.log\"))\n",
    "    mydf = mydf[mydf.Type != \"Epoch\"]\n",
    "    mydf.Timestamp += 7200\n",
    "    mydf['date'] = pd.to_datetime(mydf['Timestamp'], unit='s')\n",
    "    mydf = mydf[[\"date\", \"Accuracy\"]]\n",
    "    x = pd.read_json(path_or_buf=os.path.join(DATA_PATH, run, \"parsed-files\", \"bytes_per_sec.json\"))\n",
    "    x['date'] = pd.to_datetime(x['frame.time'], unit='ms')\n",
    "    x = x[[\"date\", \"frame.len\"]]\n",
    "    data_transmitted = x.resample(np.mean(mydf[\"date\"].diff()), on='date').sum()\n",
    "    data[run] = data_transmitted.mean()/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-donor",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [i.split(\"-\") + [float(data[i])] for i in all_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-endorsement",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [[f\"{l[0]}_{l[4]}\", l[1], l[2], l[3], l[5], l[6], l[7]] for l in parameters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-adoption",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(parameters, columns = ['framework_backend', 'model', 'optimizer', 'bsize', 'delay', 'topology', 'data'])\n",
    "\n",
    "mapping = {\"mobilenetv2\": 14, \"densenet201\": 80, \"resnet50\": 98, \"resnet101\": 171}\n",
    "mapping2 = {\"mobilenetv2\": 3.5, \"densenet201\": 20, \"resnet50\": 26, \"resnet101\": 45}\n",
    "df['model_size'] = df['model'].apply(lambda x: mapping[x])\n",
    "df['no_param'] = df['model'].apply(lambda x: mapping2[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-monitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['model_size', 'framework_backend', 'bsize', 'topology']]\n",
    "y = df['data']\n",
    "X = pd.get_dummies(data=X, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-cheese",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.LinearRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-penalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_Sm= sm.add_constant(X)\n",
    "ls=sm.OLS(y,X_train_Sm).fit()\n",
    "print(ls.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infrared-familiar",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
